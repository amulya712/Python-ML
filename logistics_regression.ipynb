{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "Researchers are often interested in setting up a model to analyze the relationship between predictors (i.e., independent variables) and it's corresponsing response (i.e., dependent variable). Linear regression is commonly used when the response variable is continuous.  One assumption of linear models is that the residual errors follow a normal distribution. This assumption fails when the response variable is categorical, so an ordinary linear model is not appropriate. This newsletter presents a regression model for response variable that is dichotomous–having two categories. Examples are common: whether a plant lives or dies, whether a survey respondent agrees or disagrees with a statement, or whether an at-risk child graduates or drops out from high school.\n",
    "\n",
    "In ordinary linear regression, the response variable (Y) is a linear function of the coefficients (B0, B1, etc.) that correspond to the predictor variables (X1, X2, etc.,). A typical model would look like:\n",
    "\n",
    "    Y = B0 + B1*X1 + B2*X2 + B3*X3 + … + E\n",
    "\n",
    "For a dichotomous response variable, we could set up a similar linear model to predict individual category memberships if numerical values are used to represent the two categories. Arbitrary values of 1 and 0 are chosen for mathematical convenience. Using the first example, we would assign Y = 1 if a plant lives and Y = 0 if a plant dies.\n",
    "\n",
    "This linear model does not work well for a few reasons. First, the response values, 0 and 1, are arbitrary, so modeling the actual values of Y is not exactly of interest. Second, it is the probability that each individual in the population responds with 0 or 1 that we are interested in modeling. For example, we may find that plants with a high level of a fungal infection (X1) fall into the category “the plant lives” (Y) less often than those plants with low level of infection. Thus, as the level of infection rises, the probability of plant living decreases.\n",
    "\n",
    "Thus, we might consider modeling P, the probability, as the response variable. Again, there are problems. Although the general decrease in probability is accompanied by a general increase in infection level, we know that P, like all probabilities, can only fall within the boundaries of 0 and 1. Consequently, it is better to assume that the relationship between X1 and P is sigmoidal (S-shaped), rather than a straight line.\n",
    "\n",
    "It is possible, however, to find a linear relationship between X1 and function of P. Although a number of functions work, one of the most useful is the logit function. It is the natural log of the odds that Y is equal to 1, which is simply the ratio of the probability that Y is 1 divided by the probability that Y is 0. The relationship between the logit of P and P itself is sigmoidal in shape. The regression equation that results is:\n",
    "\n",
    "    ln[P/(1-P)] = B0 + B1*X1 + B2*X2 + …\n",
    "\n",
    "Although the left side of this equation looks intimidating, this way of expressing the probability results in the right side of the equation being linear and looking familiar to us. This helps us understand the meaning of the regression coefficients. The coefficients can easily be transformed so that their interpretation makes sense.\n",
    "\n",
    "The logistic regression equation can be extended beyond the case of a dichotomous response variable to the cases of ordered categories and polytymous categories (more than two categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics behind Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem structure is the classic classification problem. Our data set $\\mathcal{D}$ is composed of $N$ samples. Each sample is a tuple containing a feature vector and a label. For any sample $n$ the feature vector is a $d+1$ dimensional column vector denoted by ${\\bf x}_n$ with $d$ real-valued components known as features. Samples are represented in homogeneous form with the first component equal to $1$: $x_0=1$. Vectors are bold-faced. The associated label is denoted $y_n$ and can take only two values: $+1$ or $-1$.\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\lbrace ({\\bf x}_1, y_1), ({\\bf x}_2, y_2), ..., ({\\bf x}_N, y_N) \\rbrace \\\\\n",
    "{\\bf x}_n = \\begin{bmatrix} 1 & x_1 & ... & x_d \\end{bmatrix}^T \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the name logistic *regression* this is actually a probabilistic classification model. It is also a linear model which can be subjected to nonlinear transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All linear models make use of a \"signal\" $s$ which is a linear combination of the input vector ${\\bf x}$ components weighed by the corresponding components in a weight vector ${\\bf w}$.\n",
    "\n",
    "$$\n",
    "{\\bf w} = \\begin{bmatrix} w_0 & w_1 & ... & w_d \\end{bmatrix}^T \\\\\n",
    "s = w_0 + w_1 x_1 + \\;...\\; + w_d x_d = \\sum_{i=0}^d w_i x_i = {\\bf w} \\cdot {\\bf x} = {\\bf w}^T {\\bf x}\n",
    "$$\n",
    "\n",
    "Note that the homogeneous representation (with the $1$ at the first component) allows us to include a constant offset using a more compact vector-only notation (instead of ${\\bf w}^T {\\bf x}+b$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear classification passes the signal through a harsh threshold:\n",
    "\n",
    "$$\n",
    "h({\\bf x}) = \\operatorname{sign}(s)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression uses the signal directly without modification:\n",
    "\n",
    "$$\n",
    "h({\\bf x}) = s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression passes the signal through the logistic/sigmoid but then treats the result as a probability:\n",
    "\n",
    "$$\n",
    "h({\\bf x}) = \\theta(s)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [logistic function](http://en.wikipedia.org/wiki/Logistic_function) is\n",
    "\n",
    "$$\n",
    "\\theta(s) = \\frac{e^s}{1+e^s} = \\frac{1}{1+e^{-s}}\n",
    "$$\n",
    "\n",
    "There are many other formulas that can achieve a soft threshold such as the hyperbolic tangent, but this function results in some nice simplification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that the data is generated by a noisy target.\n",
    "\n",
    "$$\n",
    "P(y\\mid{\\bf x})=\\begin{cases}\n",
    "f({\\bf x}) & \\text{for }y=+1 \\\\\n",
    "1-f({\\bf x}) & \\text{for }y=-1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this noisy target we want to learn a hypothesis $h({\\bf x})$ that best fits the above noisy target according to some error function.\n",
    "\n",
    "$$\n",
    "h({\\bf x})=\\theta({\\bf w}^T {\\bf x})\\approx f({\\bf x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the data does not tell you the probability of a label, rather it tells what label the sample has after being generated by the target distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn a good hypothesis we want to find a hypothesis parameterization ${\\bf w}$ (the weight vector) that minimizes some in-sample error measure $E_\\text{in}$.\n",
    "\n",
    "$$\n",
    "{\\bf w}_h = \\underset{{\\bf w}}{\\operatorname{argmin}} \\; E_\\text{in}({\\bf w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error measure will be used is both plausible and nice. It is based on likelihood which is the probability of generating the data given a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our hypothesis is close to our target distribution ($h\\approx f$) then we expect that probability of generating the data to be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some controversy with using likelihood. We are really looking for the most probable hypothesis given the data: $\\underset{h}{\\operatorname{argmax}} P(h\\mid{\\bf x})$. The likelihood approach is looking for the hypothesis that makes the data most probable: $\\underset{h}{\\operatorname{argmax}} P({\\bf x}\\mid h)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian approach tackles this issue using Bayes' Theorem but introduces other issues such as choosing priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the likelihood we assume the data was generated with our hypothesis $h$:\n",
    "\n",
    "$$\n",
    "P(y\\mid{\\bf x})=\\begin{cases}\n",
    "h({\\bf x}) & \\text{for }y=+1 \\\\\n",
    "1-h({\\bf x}) & \\text{for }y=-1\n",
    "\\end{cases} \\\\\n",
    "$$\n",
    "\n",
    "where $h({\\bf x})=\\theta({\\bf w}^T {\\bf x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to deal with cases so we take advantage of a nice property of the logistic function: $\\theta(-s)=1-\\theta(s)$.\n",
    "\n",
    "$$\n",
    "\\text{if } y = +1 \\text{ then } h({\\bf x}) = \\theta({\\bf w}^T {\\bf x}) = \\theta(y \\; {\\bf w}^T {\\bf x}) \\\\\n",
    "\\text{if } y = -1 \\text{ then } 1 - h({\\bf x}) = 1 - \\theta({\\bf w}^T {\\bf x}) = \\theta(- {\\bf w}^T {\\bf x}) = \\theta(y \\; {\\bf w}^T {\\bf x}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this simplification,\n",
    "\n",
    "$$\n",
    "P(y\\mid{\\bf x})=\\theta(y\\; {\\bf w}^T {\\bf x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood is defined for a data set $\\mathcal{D}$ with $N$ samples given a hypothesis (denoted arbitrarily $g$ here):\n",
    "\n",
    "$$\n",
    "L(\\mathcal{D} \\mid g) =\n",
    "\\prod_{n=1}^{N} P(y_n \\mid {\\bf x}_n) =\n",
    "\\prod_{n=1}^{N} \\theta(y_n \\; {\\bf w}_g^T {\\bf x}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finding a good hypothesis is a matter of finding a hypothesis parameterization ${\\bf w}$ that maximizes the likelihood.\n",
    "\n",
    "$$\n",
    "{\\bf w}_h =\n",
    "\\underset{{\\bf w}}{\\operatorname{argmax}} \\; L(\\mathcal{D} \\mid h) = \n",
    "\\underset{{\\bf w}}{\\operatorname{argmax}} \\; \\theta(y_n \\; {\\bf w}^T {\\bf x}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing the likelihood is equivalent to maximizing the log of the function since the natural logarithm is a monotonically increasing function:\n",
    "\n",
    "$$\n",
    "\\underset{{\\bf w}}{\\operatorname{argmax}} \\; \\ln \\left( \\prod_{n=1}^{N} \\theta(y_n \\; {\\bf w}^T {\\bf x}_n) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can maximize the above proportional to a constant as well so we'll tack on a $\\frac{1}{N}$:\n",
    "\n",
    "$$\n",
    "\\underset{{\\bf w}}{\\operatorname{argmax}} \\; \\frac{1}{N} \\ln \\left( \\prod_{n=1}^{N} \\theta(y_n \\; {\\bf w}^T {\\bf x}_n) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now maximizing that is the same as minimizing its negative:\n",
    "\n",
    "$$\n",
    "\\underset{{\\bf w}}{\\operatorname{argmin}} \\left[ -\\frac{1}{N} \\ln \\left( \\prod_{n=1}^{N} \\theta(y_n \\; {\\bf w}^T {\\bf x}_n) \\right) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we move the negative into the log and the log into the product we turn the product into a sum of logs:\n",
    "\n",
    "$$\n",
    "\\underset{{\\bf w}}{\\operatorname{argmin}} \\;\\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( \\frac{1}{\\theta(y_n \\; {\\bf w}^T {\\bf x}_n)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding the logistic function,\n",
    "\n",
    "$$\n",
    "\\underset{{\\bf w}}{\\operatorname{argmin}} \\;\\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1 + e^{y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a much nicer form for the error measure known as the \"cross-entropy\" error.\n",
    "\n",
    "$$\n",
    "E_\\text{in}({\\bf w}) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice because it can be interpreted as the average point error where the point error function is\n",
    "\n",
    "$$\n",
    "e(h({\\bf x}_n), y_n) = \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right) \\\\\n",
    "E_\\text{in}({\\bf w}) = \\frac{1}{N} \\sum_{n=1}^{N} e(h({\\bf x}_n), y_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to learn a hypothesis we'll want to perform the following optimization:\n",
    "\n",
    "$$\n",
    "{\\bf w}_h =\n",
    "\\underset{{\\bf w}}{\\operatorname{argmin}} \\; E_\\text{in}({\\bf w}) =\n",
    "\\underset{{\\bf w}}{\\operatorname{argmin}} \\;\\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1 + e^{y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm is how we search the set of possible hypotheses (hypothesis space $\\mathcal{H}$) for the best parameterization (in this case the weight vector ${\\bf w}$). This search is an optimization problem looking for the hypothesis that optimizes an error measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no sophisticted, closed-form solution like least-squares linear, so we will use gradient descent instead. Specifically we will use batch gradient descent which calculates the gradient from all data points in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, our \"cross-entropy\" error measure is convex so there is only one minimum. Thus the minimum we arrive at is the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a general method and requires twice differentiability for smoothness. It updates the parameters using a first-order approximation of the error surface.\n",
    "\n",
    "$$\n",
    "{\\bf w}_{i+1} = {\\bf w}_i + \\nabla E_\\text{in}({\\bf w}_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn we're going to minimize the following error measure using batch gradient descent.\n",
    "\n",
    "$$\n",
    "e(h({\\bf x}_n), y_n) = \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right) \\\\\n",
    "E_\\text{in}({\\bf w}) = \\frac{1}{N} \\sum_{n=1}^{N} e(h({\\bf x}_n), y_n) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the derivative of the point loss function and possibly some abuse of notation.\n",
    "\n",
    "$$\n",
    "\\frac{d}{d{\\bf w}} e(h({\\bf x}_n), y_n)\n",
    "= \\frac{-y_n \\; {\\bf x}_n \\; e^{-y_n {\\bf w}^T {\\bf x}_n}}{1 + e^{-y_n {\\bf w}^T {\\bf x}_n}}\n",
    "= -\\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}^T {\\bf x}_n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the point loss derivative we can determine the gradient of the in-sample error:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla E_\\text{in}({\\bf w})\n",
    "&= \\frac{d}{d{\\bf w}} \\left[ \\frac{1}{N} \\sum_{n=1}^N e(h({\\bf x}_n), y_n) \\right] \\\\\n",
    "&= \\frac{1}{N} \\sum_{n=1}^N \\frac{d}{d{\\bf w}} e(h({\\bf x}_n), y_n) \\\\\n",
    "&= \\frac{1}{N} \\sum_{n=1}^N \\left( - \\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}^T {\\bf x}_n}} \\right) \\\\\n",
    "&= - \\frac{1}{N} \\sum_{n=1}^N \\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}^T {\\bf x}_n}} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our weight update rule per batch gradient descent becomes\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\bf w}_{i+1} &= {\\bf w}_i - \\eta \\; \\nabla E_\\text{in}({\\bf w}_i) \\\\\n",
    "&= {\\bf w}_i - \\eta \\; \\left( - \\frac{1}{N} \\sum_{n=1}^N \\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}_i^T {\\bf x}_n}} \\right) \\\\\n",
    "&= {\\bf w}_i + \\eta \\; \\left( \\frac{1}{N} \\sum_{n=1}^N \\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}_i^T {\\bf x}_n}} \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is our learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough with the theory, now jump to the implimentation. We will look at 2 libraries for the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the same dataset as UCLA's Logit Regression tutorial to explore logistic regression in Python. Our goal will be to identify the various factors that may influence admission into graduate school.\n",
    "\n",
    "The dataset contains several columns which we can use as predictor variables:\n",
    "\n",
    "   * gpa\n",
    "   * gre score\n",
    "   * rank or prestige of an applicant's undergraduate alma mater\n",
    "   * The fourth column, admit, is our binary target variable. It indicates whether or not a candidate was admitted our not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data in\n",
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  prestige\n",
       "0        0  380  3.61         3\n",
       "1        1  660  3.67         3\n",
       "2        1  800  4.00         1\n",
       "3        1  640  3.19         4\n",
       "4        0  520  2.93         4\n",
       "..     ...  ...   ...       ...\n",
       "395      0  620  4.00         2\n",
       "396      0  560  3.04         3\n",
       "397      0  460  2.63         2\n",
       "398      0  700  3.65         2\n",
       "399      0  600  3.89         3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the 'rank' column because there is also a DataFrame method called 'rank'\n",
    "df.columns = [\"admit\", \"gre\", \"gpa\", \"prestige\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics & Looking at the data\n",
    "Now that we've got everything loaded into Python and named appropriately let's take a look at the data. We can use the pandas function which describes a summarized view of everything. There's also function for calculating the standard deviation, std.\n",
    "\n",
    "A feature I really like in pandas is the pivot_table/crosstab aggregations. crosstab makes it really easy to do multidimensional frequency tables. You might want to play around with this to look at different cuts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa   prestige\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige   1   2   3   4\n",
       "admit                   \n",
       "0         28  97  93  55\n",
       "1         33  54  28  12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table cutting presitge and whether or not someone was admitted\n",
    "pd.crosstab(df['admit'], df['prestige'], rownames=['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'admit'}>,\n",
       "        <AxesSubplot:title={'center':'gre'}>],\n",
       "       [<AxesSubplot:title={'center':'gpa'}>,\n",
       "        <AxesSubplot:title={'center':'prestige'}>]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all of the columns\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### dummy variables\n",
    "pandas gives you a great deal of control over how categorical variables can be represented. We're going dummify the \"prestige\" column using get_dummies.\n",
    "\n",
    "get_dummies creates a new DataFrame with binary indicator variables for each category/option in the column specified. In this case, prestige has four levels: 1, 2, 3 and 4 (1 being most prestigious). When we call get_dummies, we get a dataframe with four columns, each of which describes one of those levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_1  prestige_2  prestige_3  prestige_4\n",
       "0           0           0           1           0\n",
       "1           0           0           1           0\n",
       "2           1           0           0           0\n",
       "3           0           0           0           1\n",
       "4           0           0           0           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummify rank\n",
    "dummy_rank = pd.get_dummies(df['prestige'], prefix='prestige')\n",
    "dummy_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige_2  prestige_3  prestige_4\n",
       "0      0  380  3.61           0           1           0\n",
       "1      1  660  3.67           0           1           0\n",
       "2      1  800  4.00           0           0           0\n",
       "3      1  640  3.19           0           0           1\n",
       "4      0  520  2.93           0           0           1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dummy_rank.loc[:,'prestige_2':])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  prestige_2  prestige_3  prestige_4  intercept\n",
       "0        0  380  3.61           0           1           0        1.0\n",
       "1        1  660  3.67           0           1           0        1.0\n",
       "2        1  800  4.00           0           0           0        1.0\n",
       "3        1  640  3.19           0           0           1        1.0\n",
       "4        0  520  2.93           0           0           1        1.0\n",
       "..     ...  ...   ...         ...         ...         ...        ...\n",
       "395      0  620  4.00           1           0           0        1.0\n",
       "396      0  560  3.04           0           1           0        1.0\n",
       "397      0  460  2.63           1           0           0        1.0\n",
       "398      0  700  3.65           1           0           0        1.0\n",
       "399      0  600  3.89           0           1           0        1.0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that's done, we merge the new dummy columns with the original dataset and get rid of the prestige column which we no longer need.\n",
    "\n",
    "Lastly we're going to add a constant term for our logistic regression. The statsmodels function we would use requires intercepts/constants to be specified explicitly.\n",
    "\n",
    "### Performing the regression\n",
    "Actually doing the logistic regression is quite simple. Specify the column containing the variable you're trying to predict followed by the columns that the model should use to make the prediction.\n",
    "\n",
    "In our case we'll be predicting the admit column using gre, gpa, and the prestige dummy variables prestige_2, prestige_3 and prestige_4. We're going to treat prestige_1 as our baseline and exclude it from our fit. This is done to prevent multicollinearity, or the dummy variable trap caused by including a dummy variable for every single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "train_cols = data.columns[1:]\n",
    "# Index([gre, gpa, prestige_2, prestige_3, prestige_4], dtype=object)\n",
    "\n",
    "logit = sm.Logit(data['admit'], data[train_cols])\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing a logistic regression, we're going to use the statsmodels Logit function. For details on other models available in statsmodels, check out their docs here.\n",
    "\n",
    "### Interpreting the results\n",
    "One of my favorite parts about statsmodels is the summary output it gives. If you're coming from R, I think you'll like the output and find it very familiar too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>admit</td>      <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   394</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 07 Sep 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.08292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:31:02</td>     <th>  Log-Likelihood:    </th> <td> -229.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -249.99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>7.578e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>        <td>    0.0023</td> <td>    0.001</td> <td>    2.070</td> <td> 0.038</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>        <td>    0.8040</td> <td>    0.332</td> <td>    2.423</td> <td> 0.015</td> <td>    0.154</td> <td>    1.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2</th> <td>   -0.6754</td> <td>    0.316</td> <td>   -2.134</td> <td> 0.033</td> <td>   -1.296</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3</th> <td>   -1.3402</td> <td>    0.345</td> <td>   -3.881</td> <td> 0.000</td> <td>   -2.017</td> <td>   -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4</th> <td>   -1.5515</td> <td>    0.418</td> <td>   -3.713</td> <td> 0.000</td> <td>   -2.370</td> <td>   -0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -3.9900</td> <td>    1.140</td> <td>   -3.500</td> <td> 0.000</td> <td>   -6.224</td> <td>   -1.756</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      394\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 07 Sep 2021   Pseudo R-squ.:                 0.08292\n",
       "Time:                        14:31:02   Log-Likelihood:                -229.26\n",
       "converged:                       True   LL-Null:                       -249.99\n",
       "Covariance Type:            nonrobust   LLR p-value:                 7.578e-08\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "gre            0.0023      0.001      2.070      0.038       0.000       0.004\n",
       "gpa            0.8040      0.332      2.423      0.015       0.154       1.454\n",
       "prestige_2    -0.6754      0.316     -2.134      0.033      -1.296      -0.055\n",
       "prestige_3    -1.3402      0.345     -3.881      0.000      -2.017      -0.663\n",
       "prestige_4    -1.5515      0.418     -3.713      0.000      -2.370      -0.733\n",
       "intercept     -3.9900      1.140     -3.500      0.000      -6.224      -1.756\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset I chose is the [affairs dataset](http://statsmodels.sourceforge.net/stable/datasets/generated/fair.html) that comes with [Statsmodels](http://statsmodels.sourceforge.net/). It was derived from a survey of women in 1974 by Redbook magazine, in which married women were asked about their participation in extramarital affairs. More information about the study is available in a [1978 paper](http://fairmodel.econ.yale.edu/rayfair/pdf/1978a200.pdf) from the Journal of Political Economy.\n",
    "\n",
    "## Description of Variables\n",
    "\n",
    "The dataset contains 6366 observations of 9 variables:\n",
    "\n",
    "* `rate_marriage`: woman's rating of her marriage (1 = very poor, 5 = very good)\n",
    "* `age`: woman's age\n",
    "* `yrs_married`: number of years married\n",
    "* `children`: number of children\n",
    "* `religious`: woman's rating of how religious she is (1 = not religious, 4 = strongly religious)\n",
    "* `educ`: level of education (9 = grade school, 12 = high school, 14 = some college, 16 = college graduate, 17 = some graduate school, 20 = advanced degree)\n",
    "* `occupation`: woman's occupation (1 = student, 2 = farming/semi-skilled/unskilled, 3 = \"white collar\", 4 = teacher/nurse/writer/technician/skilled, 5 = managerial/business, 6 = professional with advanced degree)\n",
    "* `occupation_husb`: husband's occupation (same coding as above)\n",
    "* `affairs`: time spent in extra-marital affairs\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "I decided to treat this as a classification problem by creating a new binary variable `affair` (did the woman have at least one affair?) and trying to predict the classification for each woman.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "First, let's load the dataset and add a binary `affair` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
      "0               3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
      "1               3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
      "2               4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
      "3               4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
      "4               5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
      "...             ...   ...          ...       ...        ...   ...         ...   \n",
      "6361            5.0  32.0         13.0       2.0        3.0  17.0         4.0   \n",
      "6362            4.0  32.0         13.0       1.0        1.0  16.0         5.0   \n",
      "6363            5.0  22.0          2.5       0.0        2.0  14.0         3.0   \n",
      "6364            5.0  32.0          6.0       1.0        3.0  14.0         3.0   \n",
      "6365            4.0  22.0          2.5       0.0        2.0  16.0         2.0   \n",
      "\n",
      "      occupation_husb   affairs  \n",
      "0                 5.0  0.111111  \n",
      "1                 4.0  3.230769  \n",
      "2                 5.0  1.400000  \n",
      "3                 5.0  0.727273  \n",
      "4                 4.0  4.666666  \n",
      "...               ...       ...  \n",
      "6361              3.0  0.000000  \n",
      "6362              5.0  0.000000  \n",
      "6363              1.0  0.000000  \n",
      "6364              4.0  0.000000  \n",
      "6365              4.0  0.000000  \n",
      "\n",
      "[6366 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "print(dta)\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affairs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.329701</td>\n",
       "      <td>28.390679</td>\n",
       "      <td>7.989335</td>\n",
       "      <td>1.238813</td>\n",
       "      <td>2.504521</td>\n",
       "      <td>14.322977</td>\n",
       "      <td>3.405286</td>\n",
       "      <td>3.833758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.647345</td>\n",
       "      <td>30.537019</td>\n",
       "      <td>11.152460</td>\n",
       "      <td>1.728933</td>\n",
       "      <td>2.261568</td>\n",
       "      <td>13.972236</td>\n",
       "      <td>3.463712</td>\n",
       "      <td>3.884559</td>\n",
       "      <td>2.187243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rate_marriage        age  yrs_married  children  religious       educ  \\\n",
       "affair                                                                          \n",
       "0            4.329701  28.390679     7.989335  1.238813   2.504521  14.322977   \n",
       "1            3.647345  30.537019    11.152460  1.728933   2.261568  13.972236   \n",
       "\n",
       "        occupation  occupation_husb   affairs  \n",
       "affair                                         \n",
       "0         3.405286         3.833758  0.000000  \n",
       "1         3.463712         3.884559  2.187243  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.groupby('affair').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average, women who have affairs rate their marriages lower, which is to be expected. Let's take another look at the `rate_marriage` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affairs</th>\n",
       "      <th>affair</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_marriage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>33.823232</td>\n",
       "      <td>13.914141</td>\n",
       "      <td>2.308081</td>\n",
       "      <td>2.343434</td>\n",
       "      <td>13.848485</td>\n",
       "      <td>3.232323</td>\n",
       "      <td>3.838384</td>\n",
       "      <td>1.201671</td>\n",
       "      <td>0.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>30.471264</td>\n",
       "      <td>10.727011</td>\n",
       "      <td>1.735632</td>\n",
       "      <td>2.330460</td>\n",
       "      <td>13.864943</td>\n",
       "      <td>3.327586</td>\n",
       "      <td>3.764368</td>\n",
       "      <td>1.615745</td>\n",
       "      <td>0.635057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>30.008056</td>\n",
       "      <td>10.239174</td>\n",
       "      <td>1.638469</td>\n",
       "      <td>2.308157</td>\n",
       "      <td>14.001007</td>\n",
       "      <td>3.402820</td>\n",
       "      <td>3.798590</td>\n",
       "      <td>1.371281</td>\n",
       "      <td>0.550856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>28.856601</td>\n",
       "      <td>8.816905</td>\n",
       "      <td>1.369536</td>\n",
       "      <td>2.400981</td>\n",
       "      <td>14.144514</td>\n",
       "      <td>3.420161</td>\n",
       "      <td>3.835861</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.322926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>28.574702</td>\n",
       "      <td>8.311662</td>\n",
       "      <td>1.252794</td>\n",
       "      <td>2.506334</td>\n",
       "      <td>14.399776</td>\n",
       "      <td>3.454918</td>\n",
       "      <td>3.892697</td>\n",
       "      <td>0.348174</td>\n",
       "      <td>0.181446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  yrs_married  children  religious       educ  \\\n",
       "rate_marriage                                                           \n",
       "1.0            33.823232    13.914141  2.308081   2.343434  13.848485   \n",
       "2.0            30.471264    10.727011  1.735632   2.330460  13.864943   \n",
       "3.0            30.008056    10.239174  1.638469   2.308157  14.001007   \n",
       "4.0            28.856601     8.816905  1.369536   2.400981  14.144514   \n",
       "5.0            28.574702     8.311662  1.252794   2.506334  14.399776   \n",
       "\n",
       "               occupation  occupation_husb   affairs    affair  \n",
       "rate_marriage                                                   \n",
       "1.0              3.232323         3.838384  1.201671  0.747475  \n",
       "2.0              3.327586         3.764368  1.615745  0.635057  \n",
       "3.0              3.402820         3.798590  1.371281  0.550856  \n",
       "4.0              3.420161         3.835861  0.674837  0.322926  \n",
       "5.0              3.454918         3.892697  0.348174  0.181446  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.groupby('rate_marriage').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An increase in `age`, `yrs_married`, and `children` appears to correlate with a declining marriage rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with histograms of education and marriage rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of education\n",
    "dta.educ.hist()\n",
    "plt.title('Histogram of Education')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of marriage rating\n",
    "dta.rate_marriage.hist()\n",
    "plt.title('Histogram of marriage rating')\n",
    "plt.xlabel('Marriage Rating')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of marriage ratings for those having affairs versus those not having affairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# barplot of marriage rating grouped by affair (True or False)\n",
    "pd.crosstab(dta.rate_marriage, dta.affair.astype(bool)).plot(kind='bar')\n",
    "plt.title('Marriage Rating Distribution by Affair Status')\n",
    "plt.xlabel('Marriage Rating')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a stacked barplot to look at the percentage of women having affairs by number of years of marriage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "affair_yrs_married = pd.crosstab(dta.yrs_married, dta.affair.astype(bool))\n",
    "affair_yrs_married.div(affair_yrs_married.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Affair Percentage by Years Married')\n",
    "plt.xlabel('Years Married')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Logistic Regression\n",
    "\n",
    "To prepare the data, I want to add an intercept column as well as dummy variables for `occupation` and `occupation_husb`, since I'm treating them as categorial variables. The dmatrices function from the [patsy module](http://patsy.readthedocs.org/en/latest/) can do that using formula language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Intercept', 'C(occupation)[T.2.0]', 'C(occupation)[T.3.0]',\n",
       "       'C(occupation)[T.4.0]', 'C(occupation)[T.5.0]', 'C(occupation)[T.6.0]',\n",
       "       'C(occupation_husb)[T.2.0]', 'C(occupation_husb)[T.3.0]',\n",
       "       'C(occupation_husb)[T.4.0]', 'C(occupation_husb)[T.5.0]',\n",
       "       'C(occupation_husb)[T.6.0]', 'rate_marriage', 'age', 'yrs_married',\n",
       "       'children', 'religious', 'educ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframes with an intercept column and dummy variables for\n",
    "# occupation and occupation_husb\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + \\\n",
    "                    religious + educ + C(occupation) + C(occupation_husb)', \n",
    "                dta, return_type=\"dataframe\")\n",
    "X.columns\n",
    "#y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names for the dummy variables are ugly, so let's rename those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column names of X\n",
    "X=X.rename(columns={'C(occupation)[t,2,0]':'occ_2',\n",
    "                    'C(occupation)[t,3,0]':'occ_3',\n",
    "                    'C(occupation)[t,4,0]':'occ_4',\n",
    "                    'C(occupation)[t,5,0]':'occ_5',\n",
    "                    'C(occupation)[t,6,0]':'occ_6',\n",
    "                    'C(occupation_husb)[t,2,0]':'occ_2',\n",
    "                    'C(occupation_husb)[t,3,0]':'occ_3',\n",
    "                    'C(occupation_husb)[t,4,0]':'occ_4',\n",
    "                    'C(occupation_husb)[t,5,0]':'occ_5',\n",
    "                    'C(occupation_husb)[t,6,0]':'occ_6'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to flatten `y` into a 1-D array, so that scikit-learn will properly understand it as the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affairs</th>\n",
       "      <th>affair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6366 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0               3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1               3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2               4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3               4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4               5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "...             ...   ...          ...       ...        ...   ...         ...   \n",
       "6361            5.0  32.0         13.0       2.0        3.0  17.0         4.0   \n",
       "6362            4.0  32.0         13.0       1.0        1.0  16.0         5.0   \n",
       "6363            5.0  22.0          2.5       0.0        2.0  14.0         3.0   \n",
       "6364            5.0  32.0          6.0       1.0        3.0  14.0         3.0   \n",
       "6365            4.0  22.0          2.5       0.0        2.0  16.0         2.0   \n",
       "\n",
       "      occupation_husb   affairs  affair  \n",
       "0                 5.0  0.111111       1  \n",
       "1                 4.0  3.230769       1  \n",
       "2                 5.0  1.400000       1  \n",
       "3                 5.0  0.727273       1  \n",
       "4                 4.0  4.666666       1  \n",
       "...               ...       ...     ...  \n",
       "6361              3.0  0.000000       0  \n",
       "6362              5.0  0.000000       0  \n",
       "6363              1.0  0.000000       0  \n",
       "6364              4.0  0.000000       0  \n",
       "6365              4.0  0.000000       0  \n",
       "\n",
       "[6366 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y)\n",
    "dta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's go ahead and run logistic regression on the entire data set, and see how accurate it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7258875274897895"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X,y)\n",
    "# check the accuracy on the training set\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73% accuracy seems good, but what's the null error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3224945020420987"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what percentage had affairs?\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 32% of the women had affairs, which means that you could obtain 68% accuracy by always predicting \"no\". So we're doing better than the null error rate, but not by much.\n",
    "\n",
    "Let's examine the coefficients to see what we learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Intercept', 'C(occupation)[T.2.0]', 'C(occupation)[T.3.0]',\n",
       "        'C(occupation)[T.4.0]', 'C(occupation)[T.5.0]', 'C(occupation)[T.6.0]',\n",
       "        'C(occupation_husb)[T.2.0]', 'C(occupation_husb)[T.3.0]',\n",
       "        'C(occupation_husb)[T.4.0]', 'C(occupation_husb)[T.5.0]',\n",
       "        'C(occupation_husb)[T.6.0]', 'rate_marriage', 'age', 'yrs_married',\n",
       "        'children', 'religious', 'educ'],\n",
       "       dtype='object'),\n",
       " array([[ 1.46548738],\n",
       "        [ 0.12657802],\n",
       "        [ 0.37810294],\n",
       "        [ 0.12990433],\n",
       "        [ 0.71109988],\n",
       "        [ 0.33660998],\n",
       "        [ 0.28398126],\n",
       "        [ 0.41153799],\n",
       "        [ 0.24690044],\n",
       "        [ 0.28477491],\n",
       "        [ 0.34445279],\n",
       "        [-0.70175371],\n",
       "        [-0.05908544],\n",
       "        [ 0.10732752],\n",
       "        [ 0.00748988],\n",
       "        [-0.37444329],\n",
       "        [ 0.00801047]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "X.columns, np.transpose(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increases in marriage rating and religiousness correspond to a decrease in the likelihood of having an affair. For both, wife's occupation and the husband's occupation, the lowest likelihood of having an affair corresponds to the baseline occupation (student), since all of the dummy coefficients are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Using a Validation Set\n",
    "\n",
    "So far, we have trained and tested on the same set. Let's instead split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,\n",
    "                                                   random_state=0)\n",
    "mode12=LogisticRegression()\n",
    "mode12.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to predict class labels for the test set. We will also generate the class probabilities, just to take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict class labels for the test set\n",
    "predicted = mode12.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35118422, 0.64881578],\n",
       "       [0.90467522, 0.09532478],\n",
       "       [0.71564031, 0.28435969],\n",
       "       ...,\n",
       "       [0.53460435, 0.46539565],\n",
       "       [0.82916749, 0.17083251],\n",
       "       [0.73946421, 0.26053579]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class probabilities\n",
    "probs=mode12.predict_proba(X_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the classifier is predicting a 1 (having an affair) any time the probability in the second column is greater than 0.5.\n",
    "\n",
    "Now let's generate some evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731413612565445\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print(metrics.accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 73%, which is the same as we experienced when training and predicting on the same data.\n",
    "\n",
    "We can also see the confusion matrix and a classification report with other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Using Cross-Validation\n",
    "\n",
    "Now let's try 10-fold cross-validation, to see if the accuracy holds up more rigorously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Amulya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.72370487, 0.69544741, 0.73783359, 0.70643642, 0.71428571,\n",
       "        0.73155416, 0.72955975, 0.71069182, 0.74842767, 0.74842767]),\n",
       " 0.7246369084644018)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores=cross_val_score(LogisticRegression(),X,y,\n",
    "                       scoring='accuracy',cv=10)\n",
    "scores,scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. It's still performing at 73% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Probability of an Affair\n",
    "\n",
    "Just for fun, let's predict the probability of an affair for a random woman not present in the dataset. She's a 25-year-old teacher who graduated from college, has been married for 3 years. She has 1 child, rates herself as strongly religious, rates her marriage as fair, and her husband is a farmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(occupation)[T.2.0]</th>\n",
       "      <th>C(occupation)[T.3.0]</th>\n",
       "      <th>C(occupation)[T.4.0]</th>\n",
       "      <th>C(occupation)[T.5.0]</th>\n",
       "      <th>C(occupation)[T.6.0]</th>\n",
       "      <th>C(occupation_husb)[T.2.0]</th>\n",
       "      <th>C(occupation_husb)[T.3.0]</th>\n",
       "      <th>C(occupation_husb)[T.4.0]</th>\n",
       "      <th>C(occupation_husb)[T.5.0]</th>\n",
       "      <th>C(occupation_husb)[T.6.0]</th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4456 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Intercept  C(occupation)[T.2.0]  C(occupation)[T.3.0]  \\\n",
       "2411        1.0                   1.0                   0.0   \n",
       "4083        1.0                   0.0                   1.0   \n",
       "3196        1.0                   0.0                   1.0   \n",
       "3035        1.0                   0.0                   1.0   \n",
       "1772        1.0                   0.0                   0.0   \n",
       "...         ...                   ...                   ...   \n",
       "4931        1.0                   1.0                   0.0   \n",
       "3264        1.0                   1.0                   0.0   \n",
       "1653        1.0                   0.0                   1.0   \n",
       "2607        1.0                   0.0                   1.0   \n",
       "2732        1.0                   0.0                   1.0   \n",
       "\n",
       "      C(occupation)[T.4.0]  C(occupation)[T.5.0]  C(occupation)[T.6.0]  \\\n",
       "2411                   0.0                   0.0                   0.0   \n",
       "4083                   0.0                   0.0                   0.0   \n",
       "3196                   0.0                   0.0                   0.0   \n",
       "3035                   0.0                   0.0                   0.0   \n",
       "1772                   0.0                   1.0                   0.0   \n",
       "...                    ...                   ...                   ...   \n",
       "4931                   0.0                   0.0                   0.0   \n",
       "3264                   0.0                   0.0                   0.0   \n",
       "1653                   0.0                   0.0                   0.0   \n",
       "2607                   0.0                   0.0                   0.0   \n",
       "2732                   0.0                   0.0                   0.0   \n",
       "\n",
       "      C(occupation_husb)[T.2.0]  C(occupation_husb)[T.3.0]  \\\n",
       "2411                        0.0                        0.0   \n",
       "4083                        0.0                        0.0   \n",
       "3196                        0.0                        0.0   \n",
       "3035                        0.0                        0.0   \n",
       "1772                        0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "4931                        0.0                        0.0   \n",
       "3264                        1.0                        0.0   \n",
       "1653                        0.0                        0.0   \n",
       "2607                        0.0                        0.0   \n",
       "2732                        1.0                        0.0   \n",
       "\n",
       "      C(occupation_husb)[T.4.0]  C(occupation_husb)[T.5.0]  \\\n",
       "2411                        0.0                        0.0   \n",
       "4083                        0.0                        1.0   \n",
       "3196                        0.0                        1.0   \n",
       "3035                        1.0                        0.0   \n",
       "1772                        1.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "4931                        1.0                        0.0   \n",
       "3264                        0.0                        0.0   \n",
       "1653                        1.0                        0.0   \n",
       "2607                        0.0                        1.0   \n",
       "2732                        0.0                        0.0   \n",
       "\n",
       "      C(occupation_husb)[T.6.0]  rate_marriage   age  yrs_married  children  \\\n",
       "2411                        1.0            5.0  27.0          6.0       1.0   \n",
       "4083                        0.0            4.0  42.0         23.0       4.0   \n",
       "3196                        0.0            5.0  37.0         23.0       4.0   \n",
       "3035                        0.0            5.0  22.0          2.5       0.0   \n",
       "1772                        0.0            3.0  22.0          2.5       0.0   \n",
       "...                         ...            ...   ...          ...       ...   \n",
       "4931                        0.0            3.0  27.0          2.5       1.0   \n",
       "3264                        0.0            4.0  17.5          0.5       0.0   \n",
       "1653                        0.0            3.0  22.0          2.5       0.0   \n",
       "2607                        0.0            5.0  22.0          0.5       0.0   \n",
       "2732                        0.0            4.0  22.0          2.5       0.0   \n",
       "\n",
       "      religious  educ  \n",
       "2411        2.0  16.0  \n",
       "4083        3.0  14.0  \n",
       "3196        2.0  14.0  \n",
       "3035        2.0  12.0  \n",
       "1772        3.0  14.0  \n",
       "...         ...   ...  \n",
       "4931        2.0  14.0  \n",
       "3264        2.0  12.0  \n",
       "1653        2.0  14.0  \n",
       "2607        2.0  14.0  \n",
       "2732        1.0  12.0  \n",
       "\n",
       "[4456 rows x 17 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77549058, 0.22450942]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(np.array([[1,0,0,1,0,0,1,0,0,0,0,3,25,3,1,4,16]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probability of an affair is 23%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
